{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c59e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87a616",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cd4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('data/tweets_train.pkl')\n",
    "test_df = pd.read_pickle('data/tweets_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e1948f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         hashtag  tweet_id  \\\n",
       "0                     [Snapchat]  0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "3                             []  0x1cd5b0   \n",
       "5      [authentic, LaughOutLoud]  0x1d755c   \n",
       "6                             []  0x2c91a8   \n",
       "\n",
       "                                                text train_or_test  \\\n",
       "0  People who post \"add me on #Snapchat\" must be ...         train   \n",
       "1  @brianklaas As we see, Trump is dangerous to #...         train   \n",
       "3                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>         train   \n",
       "5  @RISKshow @TheKevinAllison Thx for the BEST TI...         train   \n",
       "6       Still waiting on those supplies Liscus. <LH>         train   \n",
       "\n",
       "          class  \n",
       "0  anticipation  \n",
       "1       sadness  \n",
       "3          fear  \n",
       "5           joy  \n",
       "6  anticipation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01aa0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = train_df.text.tolist()[:20]\n",
    "# classes = train_df['class'].tolist()[:20]\n",
    "# for i in range(len(texts)):\n",
    "#     print(f\"{texts[i]}\\n{classes[i]}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19997560",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['sadness', 'anger', 'anticipation', 'fear', 'joy', 'disgust', 'surprise', 'trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf8e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_amount_dict = {}\n",
    "for c in CLASSES:\n",
    "    class_amount_dict[c] = len(train_df.loc[train_df['class'] == c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437f5257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sadness': 193437,\n",
       " 'anger': 39867,\n",
       " 'anticipation': 248935,\n",
       " 'fear': 63999,\n",
       " 'joy': 516017,\n",
       " 'disgust': 139101,\n",
       " 'surprise': 48729,\n",
       " 'trust': 205478}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_amount_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12002d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = train_df.groupby(\"class\").sample(n=class_amount_dict['anger'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ddff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_pickle('data/tweets_train_balanced.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e852182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c51aa452",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sample_df['text'], sample_df['class'], test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f71fd7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15947"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8745c17e",
   "metadata": {},
   "source": [
    "### Try Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0549ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "## Note: this model is very huge, this will take some time ...\n",
    "model_path = \"data/GoogleNews-vectors-negative300.bin.gz\"\n",
    "w2v_google_model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e65f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "594dc81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.np_utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef33fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tok = Tokenizer()\n",
    "tok.fit_on_texts(pd.concat([train_df,test_df],ignore_index=True)['text'])\n",
    "vocab_size = len(tok.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cc60b288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411972"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a28f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "convertable_count = 0\n",
    "embedding_matrix = np.zeros((vocab_size, 300)) # vocab size\n",
    "for k,v in tok.word_index.items():\n",
    "    for mod in [k, k.capitalize(), k.upper()]:\n",
    "        try:\n",
    "            vec = w2v_google_model.get_vector(mod)\n",
    "            embedding_matrix[v] = vec\n",
    "            convertable_count += 1\n",
    "            break\n",
    "        except KeyError as e:\n",
    "            continue   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a43834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_sents = tok.texts_to_sequences(x_train)\n",
    "test_encoded_sents = tok.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e54a4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get max seq length\n",
    "train_lens = [len(seq) for seq in train_encoded_sents]\n",
    "test_lens = [len(seq) for seq in test_encoded_sents]\n",
    "max_len = max([max(train_lens), max(test_lens)])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca976cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train = pad_sequences(train_encoded_sents, maxlen=max_len, padding='post')\n",
    "X_test= pad_sequences(test_encoded_sents, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8078bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7bff01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = w2v_google_model.vectors.shape[1]\n",
    "keras_model = Sequential()\n",
    "\n",
    "emb_layer = Embedding(input_dim=vocab_size, output_dim=output_dim, input_length=max_len, trainable=False, embeddings_initializer=Constant(embedding_matrix))\n",
    "keras_model.add(emb_layer)\n",
    "keras_model.add(LSTM(output_dim))\n",
    "keras_model.add(Dense(len(class_amount_dict), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7df8453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 44, 300)           321244500 \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 300)               721200    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 2408      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,968,108\n",
      "Trainable params: 723,608\n",
      "Non-trainable params: 321,244,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(keras_model.summary())\n",
    "keras_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba5c1644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "9469/9469 [==============================] - 1671s 176ms/step - loss: 1.6959 - accuracy: 0.3418 - val_loss: 1.5122 - val_accuracy: 0.4393\n",
      "Epoch 2/9\n",
      "9469/9469 [==============================] - 1682s 178ms/step - loss: 1.4490 - accuracy: 0.4630 - val_loss: 1.4127 - val_accuracy: 0.4803\n",
      "Epoch 3/9\n",
      "9469/9469 [==============================] - 1638s 173ms/step - loss: 1.3570 - accuracy: 0.5004 - val_loss: 1.3713 - val_accuracy: 0.4905\n",
      "Epoch 4/9\n",
      "9469/9469 [==============================] - 1602s 169ms/step - loss: 1.2820 - accuracy: 0.5297 - val_loss: 1.3622 - val_accuracy: 0.5017\n",
      "Epoch 5/9\n",
      "9469/9469 [==============================] - 1536s 162ms/step - loss: 1.2068 - accuracy: 0.5590 - val_loss: 1.3792 - val_accuracy: 0.4965\n",
      "Epoch 6/9\n",
      "9469/9469 [==============================] - 1447s 153ms/step - loss: 1.1269 - accuracy: 0.5904 - val_loss: 1.4221 - val_accuracy: 0.4931\n",
      "Epoch 7/9\n",
      "9469/9469 [==============================] - 6763s 714ms/step - loss: 1.0441 - accuracy: 0.6227 - val_loss: 1.4562 - val_accuracy: 0.4917\n",
      "Epoch 8/9\n",
      "9469/9469 [==============================] - 16660s 2s/step - loss: 0.9634 - accuracy: 0.6533 - val_loss: 1.5533 - val_accuracy: 0.4850\n",
      "Epoch 9/9\n",
      "9469/9469 [==============================] - 1548s 163ms/step - loss: 0.8913 - accuracy: 0.6808 - val_loss: 1.6403 - val_accuracy: 0.4822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa86ac15f90>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs = 9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a57be4",
   "metadata": {},
   "source": [
    "### Preprocess for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20437351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecb30555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"\"\"[,.\"'`~#%^*(\\)&[\\]{\\}></]\"\"\", ' ', text)\n",
    "    text = re.sub('(?<! )(?=[!?])|(?<=[!?()])(?! )', r' ', text)  # want to keep ? and !\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text).strip()\n",
    "    tokens = [tok for tok in text.split() if tok not in stopwords.words('english')]\n",
    "    tokens = [ps.stem(tok) for tok in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "674665e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9aa20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=preprocess)\n",
    "#tfidf = TfidfVectorizer()\n",
    "tfidf_embeddings = tfidf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c68985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95118743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = LinearSVC()\n",
    "svm_model.fit(tfidf_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67973461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ddec3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6fe70d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.47      0.53      0.50      1996\n",
      "anticipation       0.50      0.55      0.52      1921\n",
      "     disgust       0.43      0.42      0.42      2049\n",
      "        fear       0.54      0.57      0.55      1955\n",
      "         joy       0.40      0.39      0.40      2059\n",
      "     sadness       0.44      0.39      0.42      2048\n",
      "    surprise       0.48      0.44      0.46      1988\n",
      "       trust       0.45      0.44      0.45      1931\n",
      "\n",
      "    accuracy                           0.47     15947\n",
      "   macro avg       0.46      0.47      0.46     15947\n",
      "weighted avg       0.46      0.47      0.46     15947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_model.predict(test_embeds)\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87b4eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ff810e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svm_model, open('data/svm_nopreprocess_alldata.pkl', 'wb'))\n",
    "pickle.dump(tfidf, open('data/tfidf_nopreprocess_alldata.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e7d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
